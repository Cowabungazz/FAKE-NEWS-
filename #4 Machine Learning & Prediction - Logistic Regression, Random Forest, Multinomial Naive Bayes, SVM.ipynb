{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7a4bb9c",
   "metadata": {},
   "source": [
    "## Load the Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8187ea9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d365ac5",
   "metadata": {},
   "source": [
    "## Splitting the data into 2 parts - train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b12de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned dataset\n",
    "data = pd.read_csv('cleaned_news_data.csv')\n",
    "\n",
    "# Combine title_clean and text_clean as the input for the model\n",
    "data['combined_text'] = data['title_clean'] + ' ' + data['text_clean']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['combined_text'], data['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd42b72",
   "metadata": {},
   "source": [
    "### Create a CountVectorizer object, common english words (e.g., \"a\", \"an\", \"the\") will be removed from the text The vectorizer will use the top 10,000 most frequent words in the text to create the feature vectors.\n",
    "\n",
    "### The 'vectorizer' object is then used to fit and transform the training data (X_train) and transform the test data (X_test) into BoW feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a423c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=10000)\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a8e76",
   "metadata": {},
   "source": [
    "### Create a TfidfVectorizer object with the same stop_words and max_features parameters as before. The difference between CountVectorizer and TfidfVectorizer is that the latter calculates the Term Frequency-Inverse Document Frequency (TF-IDF) of each word, which is a measure that reflects the importance of a word in the document and the entire corpus.\n",
    "\n",
    "### The 'vectorizer_tfidf' object is then used to fit and transform the training data (X_train) and transform the test data (X_test) into TF-IDF feature vectors. These feature vectors are stored in the variables 'X_train_tfidf' and 'X_test_tfidf'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c37cdb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer\n",
    "vectorizer_tfidf = TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer_tfidf.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89611b2",
   "metadata": {},
   "source": [
    "### loads the pre-trained GloVe model with 100-dimensional word vectors\n",
    "\n",
    "### The get_average_glove_vector() function is defined, which takes a text string and the GloVe model as input arguments. Inside the function, the text is split into words. For each word, if it exists in the GloVe model, the corresponding word vector is extracted. If there are no valid word vectors in the text, the function returns a zero vector of the same size as the GloVe model's vector size. Otherwise, the function computes the average of all the word vectors in the text and returns this average vector as the final representation for the input text.\n",
    "\n",
    "### The function get_average_glove_vector() is applied to each text in the training data (X_train) and test data (X_test) using list comprehensions. The resulting arrays of average GloVe vectors are then converted to NumPy arrays and stored in the variables 'X_train_glove' and 'X_test_glove'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7bb9a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-trained word embeddings (GloVe)\n",
    "glove_model = api.load('glove-wiki-gigaword-100')\n",
    "\n",
    "def get_average_glove_vector(text, model):\n",
    "    words = text.split()\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if not word_vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "X_train_glove = np.array([get_average_glove_vector(text, glove_model) for text in X_train])\n",
    "X_test_glove = np.array([get_average_glove_vector(text, glove_model) for text in X_test])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6433e5",
   "metadata": {},
   "source": [
    "### Two dictionaries: models and inputs. To store different machine learning models and different input feature types for an NLP classification task. These dictionaries will later be used for running multiple experiments, allowing for easy comparison of model performance using different input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ede9b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and input types\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'SVM': SVC(random_state=42)\n",
    "}\n",
    "\n",
    "inputs = {\n",
    "    'Bag of Words': (X_train_bow, X_test_bow),\n",
    "    'TF-IDF': (X_train_tfidf, X_test_tfidf),\n",
    "    'GloVe': (X_train_glove, X_test_glove)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5519911",
   "metadata": {},
   "source": [
    "### Iterate over different input types (Bag of Words, TF-IDF, and GloVe) and machine learning models (Logistic Regression, Random Forest, Multinomial Naive Bayes, and SVM) to train, optimize, and evaluate their performance. The objective is to compare the performance of different models using different input feature types for a given text classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2c1d4b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tee Chang Zen\\AppData\\Local\\Temp\\ipykernel_15100\\2381932375.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance_df = performance_df.append({\n",
      "C:\\Users\\Tee Chang Zen\\AppData\\Local\\Temp\\ipykernel_15100\\2381932375.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance_df = performance_df.append({\n",
      "C:\\Users\\Tee Chang Zen\\AppData\\Local\\Temp\\ipykernel_15100\\2381932375.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance_df = performance_df.append({\n",
      "C:\\Users\\Tee Chang Zen\\AppData\\Local\\Temp\\ipykernel_15100\\2381932375.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance_df = performance_df.append({\n",
      "C:\\Users\\Tee Chang Zen\\AppData\\Local\\Temp\\ipykernel_15100\\2381932375.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance_df = performance_df.append({\n",
      "C:\\Users\\Tee Chang Zen\\AppData\\Local\\Temp\\ipykernel_15100\\2381932375.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance_df = performance_df.append({\n",
      "C:\\Users\\Tee Chang Zen\\AppData\\Local\\Temp\\ipykernel_15100\\2381932375.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance_df = performance_df.append({\n",
      "C:\\Users\\Tee Chang Zen\\AppData\\Local\\Temp\\ipykernel_15100\\2381932375.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance_df = performance_df.append({\n",
      "C:\\Users\\Tee Chang Zen\\AppData\\Local\\Temp\\ipykernel_15100\\2381932375.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance_df = performance_df.append({\n",
      "C:\\Users\\Tee Chang Zen\\AppData\\Local\\Temp\\ipykernel_15100\\2381932375.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance_df = performance_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Input Type                    Model  Accuracy  Precision    Recall  \\\n",
      "0   Bag of Words      Logistic Regression  0.994353   0.995044  0.993168   \n",
      "1   Bag of Words            Random Forest  0.996612   0.996233  0.996702   \n",
      "2   Bag of Words  Multinomial Naive Bayes  0.943867   0.941773  0.941107   \n",
      "3   Bag of Words                      SVM  0.992772   0.993858  0.991048   \n",
      "4         TF-IDF      Logistic Regression  0.985995   0.981538  0.989399   \n",
      "5         TF-IDF            Random Forest  0.996612   0.996700  0.996231   \n",
      "6         TF-IDF  Multinomial Naive Bayes  0.928507   0.929387  0.920848   \n",
      "7         TF-IDF                      SVM  0.993336   0.991776  0.994346   \n",
      "8          GloVe      Logistic Regression  0.934041   0.929191  0.933569   \n",
      "9          GloVe            Random Forest  0.946917   0.951879  0.936631   \n",
      "10         GloVe                      SVM  0.939349   0.935211  0.938516   \n",
      "\n",
      "    F1 Score  \n",
      "0   0.994105  \n",
      "1   0.996467  \n",
      "2   0.941440  \n",
      "3   0.992451  \n",
      "4   0.985453  \n",
      "5   0.996466  \n",
      "6   0.925098  \n",
      "7   0.993060  \n",
      "8   0.931375  \n",
      "9   0.944194  \n",
      "10  0.936861  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tee Chang Zen\\AppData\\Local\\Temp\\ipykernel_15100\\2381932375.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  performance_df = performance_df.append({\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Store evaluation metrics in a DataFrame\n",
    "performance_df = pd.DataFrame(columns=['Input Type', 'Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "for input_name, (X_train_input, X_test_input) in inputs.items():\n",
    "    for model_name, model in models.items():\n",
    "        #GloVe generates continuous word embeddings, while MNB works with discrete features. \n",
    "        #In the case of text classification, MNB typically uses counts of words or tokens \n",
    "        #(e.g., Term Frequency or TF-IDF representation). \n",
    "        #Mixing these two representations – continuous word embeddings and discrete feature counts – \n",
    "        #can lead to poor performance or even incompatibility when using MNB.\n",
    "        if model_name == 'Multinomial Naive Bayes' and input_name in ['GloVe']:\n",
    "            continue\n",
    "\n",
    "        model.fit(X_train_input, y_train)\n",
    "        y_pred = model.predict(X_test_input)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        performance_df = performance_df.append({\n",
    "            'Input Type': input_name,\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1\n",
    "        }, ignore_index=True)\n",
    "\n",
    "print(performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2875ff5",
   "metadata": {},
   "source": [
    "#### We can analyze the performance of each model using different input types by comparing their accuracy, precision, recall, and F1 score. The best models are those with the highest scores across these metrics.\n",
    "\n",
    "#### Here are the top models for each input type:\n",
    "\n",
    "#### Bag of Words:\n",
    "Random Forest with an accuracy of 0.996612, precision of 0.996233, recall of 0.996702, and F1 score of 0.996467.\n",
    "\n",
    "#### TF-IDF:\n",
    "Random Forest with an accuracy of 0.996612, precision of 0.996700, recall of 0.996231, and F1 score of 0.996466.\n",
    "\n",
    "#### GloVe:\n",
    "Random Forest with an accuracy of 0.946917, precision of 0.951879, recall of 0.936631, and F1 score of 0.944194.\n",
    "\n",
    "#### Overall, the Random Forest model performs the best across all input types, achieving the highest scores in accuracy, precision, recall, and F1 score. In particular, the Random Forest model with Bag of Words and TF-IDF input types have very similar and impressive performance, with accuracy and F1 scores above 0.996.\n",
    "\n",
    "#### Thus, we can consider using the Random Forest model with either the Bag of Words or TF-IDF input types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e16e066",
   "metadata": {},
   "source": [
    "## Optimisation, based on evaluation of the performance above.\n",
    "\n",
    "### Reason for choice in parameter:\n",
    "Logistic Regression:\n",
    "'C': This parameter controls the inverse of the regularization strength. Smaller values result in stronger regularization, which can help avoid overfitting. We have chosen a range of values that cover both small (stronger regularization) and large (weaker regularization) values, since our model's performance is already quite high, we've included larger values like 100, to explore less regularized models.\n",
    "'penalty': This parameter determines the type of regularization applied to the model (L1, L2). Different penalties can lead to different feature selection behavior in the model, which might affect the model's performance.\n",
    "'solver': This parameter defines the optimization algorithm used for training the model. Different solvers can perform differently depending on the problem and data size.\n",
    "\n",
    "Random Forest:\n",
    "'n_estimators': This parameter controls the number of trees in the forest. Increasing the number of trees can lead to better performance but also requires more computational resources. Since our model is already performing well, we've focused on a range of higher values.\n",
    "'max_depth': This parameter defines the maximum depth of each tree. Limiting the depth can help prevent overfitting. We have included a range of values from no limit (None) to moderately deep trees (40).\n",
    "'min_samples_split': This parameter determines the minimum number of samples required to split an internal node. Higher values help prevent overfitting but can lead to underfitting if too high.\n",
    "'min_samples_leaf': This parameter controls the minimum number of samples required to be at a leaf node. Increasing this value can help prevent overfitting by creating less complex trees.\n",
    "\n",
    "Multinomial Naive Bayes:\n",
    "'alpha': This parameter is a smoothing parameter (Laplace or Lidstone smoothing) applied to the model to handle unseen features in the test data. A range of values is provided to help find the best balance between overfitting and underfitting.\n",
    "\n",
    "SVM:\n",
    "'C': This parameter is the regularization parameter, similar to the one in logistic regression. It determines the balance between achieving a low training error and a low testing error (overfitting). We've chosen a range of values to explore different levels of regularization.\n",
    "'kernel': This parameter defines the kernel function used by the SVM. Different kernel functions can lead to different decision boundaries and affect the model's performance.\n",
    "'gamma': This parameter is the kernel coefficient for the 'rbf', 'linear' kernels. It controls the shape of the decision boundary. Including 'scale' and 'auto' in the search allows for different scaling strategies, which can impact the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bff77a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Bag of Words =====\n",
      "Optimized Logistic Regression:\n",
      "Accuracy: 0.99\n",
      "Precision: 0.99\n",
      "Recall: 0.99\n",
      "F1 Score: 0.99\n",
      "Best Parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 10}\n",
      "\n",
      "Optimized Random Forest:\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "Best Parameters: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tee Chang Zen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Multinomial Naive Bayes:\n",
      "Accuracy: 0.94\n",
      "Precision: 0.95\n",
      "Recall: 0.94\n",
      "F1 Score: 0.94\n",
      "Best Parameters: {'alpha': 0.1}\n",
      "\n",
      "Optimized SVM:\n",
      "Accuracy: 0.99\n",
      "Precision: 1.00\n",
      "Recall: 0.99\n",
      "F1 Score: 0.99\n",
      "Best Parameters: {'kernel': 'rbf', 'gamma': 'scale', 'C': 10}\n",
      "\n",
      "===== TF-IDF =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tee Chang Zen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Logistic Regression:\n",
      "Accuracy: 0.99\n",
      "Precision: 0.99\n",
      "Recall: 0.99\n",
      "F1 Score: 0.99\n",
      "Best Parameters: {'solver': 'saga', 'penalty': 'l1', 'C': 100}\n",
      "\n",
      "Optimized Random Forest:\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "Best Parameters: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 40}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tee Chang Zen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Multinomial Naive Bayes:\n",
      "Accuracy: 0.93\n",
      "Precision: 0.94\n",
      "Recall: 0.92\n",
      "F1 Score: 0.93\n",
      "Best Parameters: {'alpha': 0.1}\n",
      "\n",
      "Optimized SVM:\n",
      "Accuracy: 0.99\n",
      "Precision: 0.99\n",
      "Recall: 0.99\n",
      "F1 Score: 0.99\n",
      "Best Parameters: {'kernel': 'linear', 'gamma': 'auto', 'C': 10}\n",
      "\n",
      "===== GloVe =====\n",
      "Optimized Logistic Regression:\n",
      "Accuracy: 0.94\n",
      "Precision: 0.93\n",
      "Recall: 0.94\n",
      "F1 Score: 0.93\n",
      "Best Parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 10}\n",
      "\n",
      "Optimized Random Forest:\n",
      "Accuracy: 0.95\n",
      "Precision: 0.95\n",
      "Recall: 0.93\n",
      "F1 Score: 0.94\n",
      "Best Parameters: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None}\n",
      "\n",
      "Optimized SVM:\n",
      "Accuracy: 0.94\n",
      "Precision: 0.93\n",
      "Recall: 0.94\n",
      "F1 Score: 0.94\n",
      "Best Parameters: {'kernel': 'rbf', 'gamma': 'auto', 'C': 100}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grids for each model\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'model': models['Logistic Regression'],\n",
    "        'params': {\n",
    "                    'C': [1, 10, 100],\n",
    "                    'penalty': ['l1', 'l2'],\n",
    "                    'solver': ['liblinear', 'saga']\n",
    "                  }  # Define the appropriate parameter grid\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': models['Random Forest'],\n",
    "        'params': {\n",
    "                    'n_estimators': [100, 200],\n",
    "                    'max_depth': [None, 40],\n",
    "                    'min_samples_split': [2, 5],\n",
    "                    'min_samples_leaf': [1, 2]\n",
    "                  }  # Define the appropriate parameter grid\n",
    "    },\n",
    "    'Multinomial Naive Bayes': {\n",
    "        'model': models['Multinomial Naive Bayes'],\n",
    "        'params': {\n",
    "                    'alpha': [0.1, 1, 5]\n",
    "                  }  # Define the appropriate parameter grid\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': models['SVM'],\n",
    "        'params': {\n",
    "                    'C': [1, 10, 100],\n",
    "                    'kernel': ['linear', 'rbf'],\n",
    "                    'gamma': ['scale', 'auto']\n",
    "                  }  # Define the appropriate parameter grid\n",
    "    }\n",
    "}\n",
    "\n",
    "optimized_models = {}\n",
    "\n",
    "for input_name, (X_train_input, X_test_input) in inputs.items():\n",
    "    optimized_models[input_name] = {}\n",
    "    print(f'===== {input_name} =====')\n",
    "    for name, model_grid in param_grids.items():\n",
    "        if name == 'Multinomial Naive Bayes' and input_name == 'GloVe':\n",
    "            # Skip Multinomial Naive Bayes for non-negative input types\n",
    "            continue\n",
    "        grid_search = RandomizedSearchCV(estimator=model_grid['model'], param_distributions=model_grid['params'], cv=3, scoring='accuracy', n_jobs=-1, n_iter=5)\n",
    "        grid_search.fit(X_train_input, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred_best_model = best_model.predict(X_test_input)\n",
    "\n",
    "        optimized_models[input_name][name] = best_model\n",
    "\n",
    "        accuracy_best_model = accuracy_score(y_test, y_pred_best_model)\n",
    "        precision_best_model = precision_score(y_test, y_pred_best_model)\n",
    "        recall_best_model = recall_score(y_test, y_pred_best_model)\n",
    "        f1_best_model = f1_score(y_test, y_pred_best_model)\n",
    "\n",
    "        print(f'Optimized {name}:')\n",
    "        print(f'Accuracy: {accuracy_best_model:.2f}')\n",
    "        print(f'Precision: {precision_best_model:.2f}')\n",
    "        print(f'Recall: {recall_best_model:.2f}')\n",
    "        print(f'F1 Score: {f1_best_model:.2f}')\n",
    "        print(f'Best Parameters: {grid_search.best_params_}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3763f4ea",
   "metadata": {},
   "source": [
    "#### Note: To ignore the errors and warnings, RandomizedSearchCV can still handle these cases and still return the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1352fe04",
   "metadata": {},
   "source": [
    "## The best model is the Random Forest with Bag of Words input:\n",
    "## Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a27fcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "best_model = optimized_models['Bag of Words']['Random Forest']\n",
    "\n",
    "#Save model to file\n",
    "joblib.dump(best_model, 'best_model_rf_bow.pkl')\n",
    "\n",
    "# Bag of Words\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=10000)\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "# Save the vectorizer\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5512cc",
   "metadata": {},
   "source": [
    "# load the modeland make predictions. Tacking the problem - detection of fake news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13497c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# Load the saved model\n",
    "loaded_model = joblib.load('best_model_rf_bow.pkl')\n",
    "\n",
    "# Load the preprocessor\n",
    "vectorizer = joblib.load('vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea3f261",
   "metadata": {},
   "source": [
    "# Making sure the model works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e755c229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Use the loaded model to make predictions\n",
    "X_test_transformed = vectorizer.transform(X_test)\n",
    "y_pred_loaded_model = loaded_model.predict(X_test_transformed)\n",
    "# Calculate the performance metrics\n",
    "accuracy_loaded_model = accuracy_score(y_test, y_pred_loaded_model)\n",
    "precision_loaded_model = precision_score(y_test, y_pred_loaded_model)\n",
    "recall_loaded_model = recall_score(y_test, y_pred_loaded_model)\n",
    "f1_loaded_model = f1_score(y_test, y_pred_loaded_model)\n",
    "\n",
    "print(f'Accuracy: {accuracy_loaded_model:.2f}')\n",
    "print(f'Precision: {precision_loaded_model:.2f}')\n",
    "print(f'Recall: {recall_loaded_model:.2f}')\n",
    "print(f'F1 Score: {f1_loaded_model:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be4a732",
   "metadata": {},
   "source": [
    "# Predicting news found online, \n",
    "\n",
    "https://www.reuters.com/article/us-usa-fiscal-idUSKBN1EP0LK - copy paste sample from start to end. \n",
    "\n",
    "https://web.archive.org/web/20161115024211/http://wtoe5news.com/us-election/pope-francis-shocks-world-endorses-donald-trump-for-president-releases-statement/ - copy paste sample from start to end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7864cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your sample news text (type 0 to exit): WASHINGTON (Reuters) - The head of a conservative Republican faction in the U.S. Congress, who voted this month for a huge expansion of the national debt to pay for tax cuts, called himself a “fiscal conservative” on Sunday and urged budget restraint in 2018.  In keeping with a sharp pivot under way among Republicans, U.S. Representative Mark Meadows, speaking on CBS’ “Face the Nation,” drew a hard line on federal spending, which lawmakers are bracing to do battle over in January.  When they return from the holidays on Wednesday, lawmakers will begin trying to pass a federal budget in a fight likely to be linked to other issues, such as immigration policy, even as the November congressional election campaigns approach in which Republicans will seek to keep control of Congress.  President Donald Trump and his Republicans want a big budget increase in military spending, while Democrats also want proportional increases for non-defense “discretionary” spending on programs that support education, scientific research, infrastructure, public health and environmental protection.  “The (Trump) administration has already been willing to say: ‘We’re going to increase non-defense discretionary spending ... by about 7 percent,’” Meadows, chairman of the small but influential House Freedom Caucus, said on the program.  “Now, Democrats are saying that’s not enough, we need to give the government a pay raise of 10 to 11 percent. For a fiscal conservative, I don’t see where the rationale is. ... Eventually you run out of other people’s money,” he said.  Meadows was among Republicans who voted in late December for their party’s debt-financed tax overhaul, which is expected to balloon the federal budget deficit and add about $1.5 trillion over 10 years to the $20 trillion national debt.  “It’s interesting to hear Mark talk about fiscal responsibility,” Democratic U.S. Representative Joseph Crowley said on CBS.  Crowley said the Republican tax bill would require the United States to borrow $1.5 trillion, to be paid off by future generations, to finance tax cuts for corporations and the rich.  “This is one of the least ... fiscally responsible bills we’ve ever seen passed in the history of the House of Representatives. I think we’re going to be paying for this for many, many years to come,” Crowley said.  Republicans insist the tax package, the biggest U.S. tax overhaul in more than 30 years, will boost the economy and job growth.   FILE PHOTO: The U.S. Capitol Dome (L) building is pictured in Washington, DC, U.S. on October 4, 2013. REUTERS/Jonathan Ernst/File Photo ‘ENTITLEMENT REFORM’  House Speaker Paul Ryan, who also supported the tax bill, recently went further than Meadows, making clear in a radio interview that welfare or “entitlement reform,” as the party often calls it, would be a top Republican priority in 2018.  In Republican parlance, “entitlement” programs mean food stamps, housing assistance, Medicare and Medicaid health insurance for the elderly, poor and disabled, as well as other programs created by Washington to assist the needy.  Democrats seized on Ryan’s early December remarks, saying they showed Republicans would try to pay for their tax overhaul by seeking spending cuts for social programs.  But the goals of House Republicans may have to take a back seat to the Senate, where the votes of some Democrats will be needed to approve a budget and prevent a government shutdown.  Democrats will use their leverage in the Senate, which Republicans narrowly control, to defend both discretionary non-defense programs and social spending, while tackling the issue of the “Dreamers,” people brought illegally to the country as children.  Trump in September put a March 2018 expiration date on the Deferred Action for Childhood Arrivals, or DACA, program, which protects the young immigrants from deportation and provides them with work permits.  The president has said in recent Twitter messages he wants funding for his proposed Mexican border wall and other immigration law changes in exchange for agreeing to help the Dreamers.  Representative Debbie Dingell told CBS she did not favor linking that issue to other policy objectives, such as wall funding. “We need to do DACA clean,” she said.  On Wednesday, Trump aides will meet with congressional leaders to discuss those issues. That will be followed by a weekend of strategy sessions for Trump and Republican leaders on Jan. 6 and 7, the White House said.  Trump was also scheduled to meet on Sunday with Florida Republican Governor Rick Scott, who wants more emergency aid. The House has passed an $81 billion aid package after hurricanes in Florida, Texas and Puerto Rico, and wildfires in California. The package far exceeded the $44 billion requested by the Trump administration. The Senate has not yet voted on the aid.\n",
      "[1]\n",
      "The given news is Real.\n",
      "Enter your sample news text (type 0 to exit): Pope Francis Shocks World, Endorses Donald Trump for President, Releases Statement TOPICS:Pope Francis Endorses Donald Trump photo by Jeffrey Bruno / CC BY-SA 2.0 / cropped & photo by Gage Skidmore / CC BY-SA 3.0 / cropped photo by Jeffrey Bruno / CC BY-SA 2.0 / cropped & photo by Gage Skidmore / CC BY-SA 3.0 / cropped    97.6k Share:97.6k VATICAN CITY – News outlets around the world are reporting on the news that Pope Francis has made the unprecedented decision to endorse a US presidential candidate. His statement in support of Donald Trump was released from the Vatican this evening:  “I have been hesitant to offer any kind of support for either candidate in the US presidential election but I now feel that to not voice my concern would be a dereliction of my duty as the Holy See. A strong and free America is vitally important in maintaining a strong and free world and in that sense what happens in American elections affects us all. The Rule of Law is the backbone of the American government as it is in any nation that strives for freedom and I now fear that the Rule of Law in America has been dealt a dangerous blow. The FBI, in refusing to recommend prosecution after admitting that the law had been broken on multiple occasions by Secretary Clinton, has exposed itself as corrupted by political forces that have become far too powerful. Though I don’t agree with Mr. Trump on some issues, I feel that voting against the powerful political forces that have corrupted the entire American federal government is the only option for a nation that desires a government that is truly for the people and by the people.  For this primary reason I ask, not as the Holy Father, but as a concerned citizen of the world that Americans vote for Donald Trump for President of the United States.”  Sources within the Vatican reportedly were aware that the Pope had been discussing the possibility of voicing his concern in the US presidential election but apparently were completely unaware that he had made a decision on going forward with voicing this concern until his statement was released this evening from the Vatican. Stay tuned to WTOE 5 News for more on this breaking news.\n",
      "[0]\n",
      "The given news is Fake.\n",
      "Enter your sample news text (type 0 to exit): 0\n"
     ]
    }
   ],
   "source": [
    "def predict_fake_news(sample_text):\n",
    "    # Preprocess the sample text\n",
    "    preprocessed_sample = vectorizer.transform([sample_text])\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = loaded_model.predict(preprocessed_sample)\n",
    "    print (prediction)\n",
    "    if prediction == 1:\n",
    "        return \"Real\"\n",
    "    else:\n",
    "        return \"Fake\"\n",
    "\n",
    "# Prompt the user to enter the sample news text repeatedly\n",
    "while True:\n",
    "    sample_text = input(\"Enter your sample news text (type 0 to exit): \")\n",
    "\n",
    "    if sample_text == \"0\":\n",
    "        break\n",
    "\n",
    "    result = predict_fake_news(sample_text)\n",
    "    \n",
    "    print(f\"The given news is {result}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f70320",
   "metadata": {},
   "source": [
    "### As U.S. budget fight looms, Republicans flip their fiscal script\n",
    "True story. Thomson Reuters is dedicated to upholding the Trust Principles and to preserving its independence, integrity, and freedom from bias in the gathering and dissemination of information and news.\n",
    "\n",
    "### In 2016, a story circulated that Pope Francis made an unprecedented and shocking endorsement of Donald Trump for president.\n",
    "This story is completely false.\n",
    "The original story can be traced back to a satire website, but it took off from there and became viral.\n",
    "There were also other versions of this fake story claiming Pope Francis instead endorsed Hillary Clinton and Bernie Sanders for president."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
